{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "0. 要先去 verdict-cls-debug/uie 訓練好一個 uie 模型，把 checkpoint 放到 uie_model 內，step3再指定他才能跑，詳見verdict-cls-debug/uie/pipeline.ipynb（ckp 太大丟不到github）\n",
    "1. 進入點：verdict-cls-debug/utc/zero_shot_text_classification\n",
    "2. 很多檔案感覺都不需要，ex metric.py, modeling.py, utc_trainer.py (很多都是為了實驗存在，真正需要的檔案應該可以收斂很多)\n",
    "3. verdict-cls-debug/utc/dev 這個資料夾主要是開發時候實驗的一些拉ㄐpy檔案"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1\n",
    "merge all .json data in labelstudio_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python read_and_merge_data.py   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2\n",
    "split merged data (read_and_merge_data.py output) into data/(train, test, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python label_studio.py  --label_studio_file ./labelstudio_data/formal_data/classification.json --options ./labelstudio_data/label.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3\n",
    "用 UIE 截短長文本 （依序處理 .data/train.txt, .data/dev.txt, .data/test.txt）\n",
    "\n",
    "感覺可以更 clean code:\n",
    "- uie_preprocessin.py \n",
    "- .uie_model/filter_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python uie_preprocessing.py --dataset_path data/data_1000 --max_seq_len 768 --threshold 0.0 --uie_model_name_or_path uie_model/checkpoint-2790/ --out_folder_name processed_data_1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4\n",
    "Training\n",
    "\n",
    "note: 最大長度跟 step 3 一樣比較合理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_train.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path utc-base \\\n",
    "    --output_dir ./checkpoint/lr_1e-4 \\\n",
    "    --dataset_path ./data/processed_data_1000/data_1000 \\\n",
    "    --max_seq_length 768  \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --num_train_epochs 25 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --do_export \\\n",
    "    --export_model_dir ./checkpoint/lr_1e-4 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model macro_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --save_plm "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 跑 Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_eval.py --test_path ./data/processed_data_1000/data_1000/test.txt --max_seq_len 768 --per_device_eval_batch_size 8  --model_path ./checkpoint/lr_3e-4 --output_dir ./checkpoint/lr_3e-4/test_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UIE Pre-inference 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 python uie_inference.py --data_file_to_inference ../../verdict_sheet/data_8000.json --max_seq_len 768 --threshold 0.0 --uie_model_name_or_path uie_model/checkpoint-2790/ --out_folder_name ../../verdict_data/processed_data_8000_fp32/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UTC Inference 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python utc_inference.py --test_path ./data/processed_data_8000/processed_data.json --max_seq_len 768 --per_device_eval_batch_size 8  --model_path ./checkpoint/seed_30678 --output_dir ./inference_results/data_8000/test_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data\n",
    "\n",
    "python label_studio.py --save_dir ./all_data --splits 1 0 0 --options labelstudio_data/label.txt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run baseline utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python baseline_train.py \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path utc-base \\\n",
    "    --output_dir ./checkpoint/model_best/baseline \\\n",
    "    --dataset_path ./data/data_1000 \\\n",
    "    --max_seq_length 1024 \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --num_train_epochs 25 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --do_export \\\n",
    "    --export_model_dir ./checkpoint/model_best/baseline \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model micro_f1_score \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --save_plm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_train.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path utc-base \\\n",
    "    --output_dir ./checkpoint/model_best/baseline \\\n",
    "    --dataset_path ./data/data_1000 \\\n",
    "    --max_seq_length 1024 \\\n",
    "    --per_device_train_batch_size 4 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --num_train_epochs 25 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --do_export \\\n",
    "    --export_model_dir ./checkpoint/model_best/baseline \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model micro_f1_score \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --save_plm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_train.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path utc-base \\\n",
    "    --output_dir ./checkpoint/model_best/baseline_2048 \\\n",
    "    --dataset_path ./data/data_1000 \\\n",
    "    --max_seq_length 2048 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 2 \\\n",
    "    --num_train_epochs 25 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict \\\n",
    "    --do_export \\\n",
    "    --export_model_dir ./checkpoint/model_best/baseline_2048 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model micro_f1_score \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --save_plm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PYTHONPATH=/home/ubuntu/projects/Paddle/python:/home/ubuntu/projects/PaddleNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_train_sam.py  \\\n",
    "    --device gpu  \\\n",
    "    --logging_steps 5  \\\n",
    "    --save_steps 100   \\\n",
    "    --eval_steps 100   \\\n",
    "    --seed 1000   \\\n",
    "    --model_name_or_path utc-base   \\\n",
    "    --output_dir ./checkpoint/sam     \\\n",
    "    --dataset_path ./data/processed_data_1000/data_1000     \\\n",
    "    --max_seq_length 768      \\\n",
    "    --per_device_train_batch_size 8     \\\n",
    "    --per_device_eval_batch_size 8     \\\n",
    "    --num_train_epochs 25     \\\n",
    "    --learning_rate 1e-4     \\\n",
    "    --do_train     \\\n",
    "    --do_eval     \\\n",
    "    --do_predict     \\\n",
    "    --do_export     \\\n",
    "    --export_model_dir ./checkpoint/sam     \\\n",
    "    --overwrite_output_dir     \\\n",
    "    --disable_tqdm True     \\\n",
    "    --metric_for_best_model macro_f1     \\\n",
    "    --load_best_model_at_end  True    \\\n",
    "    --save_total_limit 1     \\\n",
    "    --save_plm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf46acb013efd0588f6afec6d5cfc3a8d59196ff594941befc7df90c31a68b6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
